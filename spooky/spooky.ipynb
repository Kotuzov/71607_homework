{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "train = pd.read_csv(\"train.zip\", index_col=['id'])\n",
    "test = pd.read_csv(\"test.zip\", index_col=['id'])\n",
    "sample_submission = pd.read_csv(\"sample_submission.zip\", index_col=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 2) (8392, 1) (8392, 3)\n",
      "{'author'}\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape, sample_submission.shape)\n",
    "print(set(train.columns) - set(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author\n",
       "id                                                               \n",
       "id26305  This process, however, afforded me no means of...    EAP\n",
       "id17569  It never once occurred to me that the fumbling...    HPL\n",
       "id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train.author = train.author.replace(['EAP', 'HPL', 'MWS'], ['Едгар', 'Хауърд', 'Мери'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96645250b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=train, x='author');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78783701,  0.79635305,  0.79509579])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer()),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(train.text, train.author)\n",
    "count_vectorizer = pipeline.steps[0][1]\n",
    "count_vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81449142  0.81673307  0.81348659]\n",
      "[-0.47678351 -0.4755887  -0.47131399]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', CountVectorizer()),\n",
    "    ('clf', MLPClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78599877  0.78577996  0.78390805]\n",
      "[-1.07137215 -1.12785611 -1.18148449]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(pipeline, train.text, train.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305    This process , however , afforded me no means ...\n",
       "id17569    It never once occurred to me that the fumbling...\n",
       "id11008    In his left hand was a gold snuff box , from w...\n",
       "id27763    How lovely is spring As we looked from Windsor...\n",
       "id12958    Finding nothing else , not even gold , the Sup...\n",
       "id22965    A youth passed in solitude , my best years spe...\n",
       "id09674    The astronomer , perhaps , at this point , too...\n",
       "id13515         The surcingle hung in ribands from my body .\n",
       "id19322    I knew that you could not say to yourself 'ste...\n",
       "id00912    I confess that neither the structure of langua...\n",
       "id16737    He shall find that I can feel my injuries ; he...\n",
       "id16607    Here we barricaded ourselves , and , for the p...\n",
       "id19764    Herbert West needed fresh bodies because his l...\n",
       "id18886    The farm like grounds extended back very deepl...\n",
       "id17189    But a glance will show the fallacy of this idea .\n",
       "id12799    He had escaped me , and I must commence a dest...\n",
       "id08441    To these speeches they gave , of course , thei...\n",
       "id13117    Her native sprightliness needed no undue excit...\n",
       "id14862    I even went so far as to speak of a slightly h...\n",
       "id20836    His facial aspect , too , was remarkable for i...\n",
       "id11411    Now the net work was not permanently fastened ...\n",
       "id08075    It was not that the sounds were hideous , for ...\n",
       "id18925    On every hand was a wilderness of balconies , ...\n",
       "id19925    With how deep a spirit of wonder and perplexit...\n",
       "id01704    These bizarre attempts at explanation were fol...\n",
       "id10125    For many prodigies and signs had taken place ,...\n",
       "id02448    All that as yet can fairly be said to be known...\n",
       "id23451    I seemed to be upon the verge of comprehension...\n",
       "id27907    Our compasses , depth gauges , and other delic...\n",
       "id08121    This the young warriors took back with them to...\n",
       "                                 ...                        \n",
       "id20955    But it was not so ; I was the same in strength...\n",
       "id01270    He then took the book himself , and read me a ...\n",
       "id22290    `` Adolphe Le Bon , clerk to Mignaud et Fils ,...\n",
       "id20272    But of the character of his remarks at the per...\n",
       "id18082    He notes every variation of face as the play p...\n",
       "id07976    They admitted they had been drunk , but both v...\n",
       "id26741    The rays of the newly risen sun poured in upon...\n",
       "id26698    To the north on the craggy precipice a few pac...\n",
       "id22265    The frauds of the banks of course I could n't ...\n",
       "id14778    He was attired , as I had expected , in a cost...\n",
       "id18823    When a fumbling came in the nearer casements h...\n",
       "id00893    But then there is the tone laconic , or curt ,...\n",
       "id08678    Average people in society and business New Eng...\n",
       "id10857    The modes and sources of this kind of error ar...\n",
       "id10563    Yet from whom has not that rude hand rent away...\n",
       "id11752    Almighty God no , no They heard they suspected...\n",
       "id26214    I hope you have not been so foolish as to take...\n",
       "id00832    These reflections made our legislators pause ,...\n",
       "id04187    Because there were some considerations of deep...\n",
       "id22378    Before going in we walked up the street , turn...\n",
       "id26790    Once my fancy was soothed with dreams of virtu...\n",
       "id14263    Nay , you may have met with another whom you m...\n",
       "id14420    My watch was still going , and told me that th...\n",
       "id03325    But these and other difficulties attending res...\n",
       "id07567    Stress of weather drove us up the Adriatic Gul...\n",
       "id17718    I could have fancied , while I looked at it , ...\n",
       "id08973    The lids clenched themselves together as if in...\n",
       "id05267    Mais il faut agir that is to say , a Frenchman...\n",
       "id17513    For an item of news like this , it strikes us ...\n",
       "id00393    He laid a gnarled claw on my shoulder , and it...\n",
       "Name: text, Length: 19579, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "explore = train.copy()\n",
    "explore.text.apply(lambda s: ' '.join(nltk.word_tokenize(s)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pipeline = Pipeline([\\n    ('features', TfidfVectorizer(analyzer = 'word',\\n                                    stop_words=nltk.corpus.stopwords.words('english'),\\n                                    ngram_range=(1, 2), \\n                                    min_df=1,\\n                                    max_df=0.7,\\n                                    lowercase=False)),\\n     ('clf', MultinomialNB(alpha=0.1))\\n])\\nprint(cross_val_score(pipeline, explore.text, explore.author, cv=3, n_jobs=3, \\n                      scoring='neg_log_loss'))\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "'''pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 2), \n",
    "                                    min_df=1,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=False)),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.text, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "def random_search():\n",
    "    params = {\n",
    "        \"clf__alpha\": [0.01, 0.1, 0.5, 1, 2]\n",
    "    }\n",
    "    params_count_word = {\"features__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "                      \"features__analyzer\": ['word'],\n",
    "                      \"features__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "                      \"features__min_df\":[2, 3, 5, 10],\n",
    "                      \"features__lowercase\": [False, True]}\n",
    "                      \n",
    "    params.update(params_count_word)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),)),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=2)\n",
    "\n",
    "    random_search.fit(train.text, train.author)\n",
    "    report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.477 (std: 0.005)\n",
      "Parameters: {'features__ngram_range': (1, 2), 'features__analyzer': 'word', 'clf__alpha': 0.01, 'features__lowercase': True, 'features__min_df': 3, 'features__max_df': 0.6}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: -0.477 (std: 0.005)\n",
      "Parameters: {'features__ngram_range': (1, 2), 'features__analyzer': 'word', 'clf__alpha': 0.01, 'features__lowercase': True, 'features__min_df': 3, 'features__max_df': 0.5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.496 (std: 0.004)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__analyzer': 'word', 'clf__alpha': 0.01, 'features__lowercase': False, 'features__min_df': 5, 'features__max_df': 0.6}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.502 (std: 0.003)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__analyzer': 'word', 'clf__alpha': 0.1, 'features__lowercase': True, 'features__min_df': 5, 'features__max_df': 1.0}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.504 (std: 0.004)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__analyzer': 'word', 'clf__alpha': 0.01, 'features__lowercase': True, 'features__min_df': 5, 'features__max_df': 0.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45755117 -0.45451807 -0.45192547]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 3), \n",
    "                                    min_df=2,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=True)),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.text, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.51980125 -0.51404569 -0.50762974]\n"
     ]
    }
   ],
   "source": [
    "# не рън-вай, че таз мреа мн се чака, а като цяло е зле\n",
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 3), \n",
    "                                    min_df=2,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=True)),\n",
    "     ('clf', MLPClassifier(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.text, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305    ThisDT processNN ,, howeverRB ,, affordedVBD m...\n",
       "id17569    ItPRP neverRB onceRB occurredVBD toTO mePRP th...\n",
       "id11008    InIN hisPRP$ leftJJ handNN wasVBD aDT goldJJ s...\n",
       "id27763    HowWRB lovelyRB isVBZ springJJ AsIN wePRP look...\n",
       "id12958    FindingVBG nothingNN elseRB ,, notRB evenRB go...\n",
       "id22965    ADT youthNN passedVBN inIN solitudeNN ,, myPRP...\n",
       "id09674    TheDT astronomerNN ,, perhapsRB ,, atIN thisDT...\n",
       "id13515    TheDT surcingleNN hungNN inIN ribandsNNS fromI...\n",
       "id19322    IPRP knewVBD thatIN youPRP couldMD notRB sayVB...\n",
       "id00912    IPRP confessVBP thatIN neitherCC theDT structu...\n",
       "id16737    HePRP shallMD findVB thatIN IPRP canMD feelVB ...\n",
       "id16607    HereRB wePRP barricadedVBD ourselvesPRP ,, and...\n",
       "id19764    HerbertNNP WestNNP neededVBD freshJJ bodiesNNS...\n",
       "id18886    TheDT farmNN likeIN groundsNNS extendedVBN bac...\n",
       "id17189    ButCC aDT glanceNN willMD showVB theDT fallacy...\n",
       "id12799    HePRP hadVBD escapedVBN mePRP ,, andCC IPRP mu...\n",
       "id08441    ToTO theseDT speechesNNS theyPRP gaveVBD ,, of...\n",
       "id13117    HerPRP$ nativeJJ sprightlinessNN neededVBD noD...\n",
       "id14862    IPRP evenRB wentVBD soRB farRB asIN toTO speak...\n",
       "id20836    HisPRP$ facialJJ aspectNN ,, tooRB ,, wasVBD r...\n",
       "id11411    NowRB theDT netJJ workNN wasVBD notRB permanen...\n",
       "id08075    ItPRP wasVBD notRB thatIN theDT soundsNNS were...\n",
       "id18925    OnIN everyDT handNN wasVBD aDT wildernessNN of...\n",
       "id19925    WithIN howWRB deepJJ aDT spiritNN ofIN wonderN...\n",
       "id01704    TheseDT bizarreJJ attemptsNNS atIN explanation...\n",
       "id10125    ForIN manyJJ prodigiesNNS andCC signsNNS hadVB...\n",
       "id02448    AllPDT thatDT asIN yetRB canMD fairlyRB beVB s...\n",
       "id23451    IPRP seemedVBD toTO beVB uponIN theDT vergeNN ...\n",
       "id27907    OurPRP$ compassesNNS ,, depthNN gaugesNNS ,, a...\n",
       "id08121    ThisDT theDT youngJJ warriorsNNS tookVBD backR...\n",
       "                                 ...                        \n",
       "id20955    ButCC itPRP wasVBD notRB soRB ;: IPRP wasVBD t...\n",
       "id01270    HePRP thenRB tookVBD theDT bookNN himselfPRP ,...\n",
       "id22290    ```` AdolpheNNP LeNNP BonNNP ,, clerkNN toTO M...\n",
       "id20272    ButCC ofIN theDT characterNN ofIN hisPRP$ rema...\n",
       "id18082    HePRP notesVBZ everyDT variationNN ofIN faceNN...\n",
       "id07976    TheyPRP admittedVBD theyPRP hadVBD beenVBN dru...\n",
       "id26741    TheDT raysNNS ofIN theDT newlyRB risenVBN sunN...\n",
       "id26698    ToTO theDT northNN onIN theDT craggyJJ precipi...\n",
       "id22265    TheDT fraudsNN ofIN theDT banksNNS ofIN course...\n",
       "id14778    HePRP wasVBD attiredVBN ,, asIN IPRP hadVBD ex...\n",
       "id18823    WhenWRB aDT fumblingNN cameVBD inIN theDT near...\n",
       "id00893    ButCC thenRB thereEX isVBZ theDT toneNN laconi...\n",
       "id08678    AverageJJ peopleNNS inIN societyNN andCC busin...\n",
       "id10857    TheDT modesNNS andCC sourcesNNS ofIN thisDT ki...\n",
       "id10563    YetRB fromIN whomWP hasVBZ notRB thatIN rudeJJ...\n",
       "id11752    AlmightyNNP GodNNP noRB ,, noDT TheyPRP heardV...\n",
       "id26214    IPRP hopeVBP youPRP haveVBP notRB beenVBN soRB...\n",
       "id00832    TheseDT reflectionsNNS madeVBD ourPRP$ legisla...\n",
       "id04187    BecauseIN thereEX wereVBD someDT consideration...\n",
       "id22378    BeforeIN goingVBG inIN wePRP walkedVBD upRP th...\n",
       "id26790    OnceRB myPRP$ fancyNN wasVBD soothedVBN withIN...\n",
       "id14263    NayNNP ,, youPRP mayMD haveVB metVBN withIN an...\n",
       "id14420    MyPRP$ watchNN wasVBD stillRB goingVBG ,, andC...\n",
       "id03325    ButCC theseDT andCC otherJJ difficultiesNNS at...\n",
       "id07567    StressNN ofIN weatherNN droveVBD usPRP upRP th...\n",
       "id17718    IPRP couldMD haveVB fanciedVBN ,, whileIN IPRP...\n",
       "id08973    TheDT lidsNNS clenchedVBD themselvesPRP togeth...\n",
       "id05267    MaisNNP ilNN fautNN agirNN thatWDT isVBZ toTO ...\n",
       "id17513    ForIN anDT itemNN ofIN newsNN likeIN thisDT ,,...\n",
       "id00393    HePRP laidVBD aDT gnarledJJ clawNN onIN myPRP$...\n",
       "Name: preprocessed, Length: 19579, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore = train.copy()\n",
    "explore['preprocessed'] = explore.text.apply(lambda s: \" \".join(\"%s%s\" % tup for tup in nltk.pos_tag(nltk.word_tokenize(s))))\n",
    "\n",
    "explore['preprocessed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42748916 -0.42438677 -0.42681112]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 3), \n",
    "                                    min_df=2,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=True)),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_search():\n",
    "    params = {\n",
    "        \"clf__alpha\": [0.01, 0.1, 0.5, 1, 2]\n",
    "    }\n",
    "    params_count_word = {\"features__ngram_range\": [(1,1), (1,2), (1,3), (1,4)],\n",
    "                      \"features__analyzer\": ['word'],\n",
    "                      \"features__max_df\":[1.0, 0.9, 0.8, 0.7, 0.6, 0.5],\n",
    "                      \"features__min_df\":[2, 3, 5, 10],\n",
    "                      \"features__lowercase\": [False, True]}\n",
    "                      \n",
    "    params.update(params_count_word)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),)),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=2)\n",
    "\n",
    "    random_search.fit(explore.preprocessed, explore.author)\n",
    "    report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.427 (std: 0.001)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__analyzer': 'word', 'clf__alpha': 0.1, 'features__lowercase': False, 'features__min_df': 2, 'features__max_df': 0.7}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.428 (std: 0.001)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__analyzer': 'word', 'clf__alpha': 0.1, 'features__lowercase': False, 'features__min_df': 2, 'features__max_df': 0.8}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.430 (std: 0.005)\n",
      "Parameters: {'features__ngram_range': (1, 2), 'features__analyzer': 'word', 'clf__alpha': 0.01, 'features__lowercase': False, 'features__min_df': 2, 'features__max_df': 0.6}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.443 (std: 0.004)\n",
      "Parameters: {'features__ngram_range': (1, 3), 'features__analyzer': 'word', 'clf__alpha': 0.01, 'features__lowercase': True, 'features__min_df': 2, 'features__max_df': 0.8}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.445 (std: 0.006)\n",
      "Parameters: {'features__ngram_range': (1, 2), 'features__analyzer': 'word', 'clf__alpha': 0.01, 'features__lowercase': False, 'features__min_df': 3, 'features__max_df': 0.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42797688 -0.421668   -0.42459543]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 2), \n",
    "                                    min_df=2,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=True)),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.52120283 -0.51131894 -0.51006827]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 3), \n",
    "                                    min_df=2,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=True)),\n",
    "     ('clf', MLPClassifier(alpha=0.1, hidden_layer_sizes = (100,)))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.text, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83884804  0.83818572  0.84030651]\n",
      "[-0.42748916 -0.42438677 -0.42681112]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 3), \n",
    "                                    min_df=2,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=True)),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>Едгар</td>\n",
       "      <td>ThisDT processNN ,, howeverRB ,, affordedVBD m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>Хауърд</td>\n",
       "      <td>ItPRP neverRB onceRB occurredVBD toTO mePRP th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  author  \\\n",
       "id                                                                   \n",
       "id26305  This process, however, afforded me no means of...   Едгар   \n",
       "id17569  It never once occurred to me that the fumbling...  Хауърд   \n",
       "\n",
       "                                              preprocessed  \n",
       "id                                                          \n",
       "id26305  ThisDT processNN ,, howeverRB ,, affordedVBD m...  \n",
       "id17569  ItPRP neverRB onceRB occurredVBD toTO mePRP th...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_backup = explore.copy()\n",
    "explore_backup.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore['phrasing'] = explore.text.apply(lambda s: \" \".join(\"%s\" % tup[1] for tup in nltk.pos_tag(nltk.word_tokenize(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305    DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...\n",
       "id17569       PRP RB RB VBD TO PRP IN DT NN MD VB DT JJ NN .\n",
       "id11008    IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN PR...\n",
       "Name: phrasing, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore['phrasing'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/kotuzov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore['lemmatized'] = explore.text.apply(lambda s: \" \".join(\"%s\" % lemmatizer.lemmatize(word) for word in nltk.word_tokenize(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305    This process , however , afforded me no mean o...\n",
       "id17569    It never once occurred to me that the fumbling...\n",
       "id11008    In his left hand wa a gold snuff box , from wh...\n",
       "Name: lemmatized, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore['lemmatized'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>phrasing</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>Едгар</td>\n",
       "      <td>ThisDT processNN ,, howeverRB ,, affordedVBD m...</td>\n",
       "      <td>DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...</td>\n",
       "      <td>This process , however , afforded me no mean o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text author  \\\n",
       "id                                                                  \n",
       "id26305  This process, however, afforded me no means of...  Едгар   \n",
       "\n",
       "                                              preprocessed  \\\n",
       "id                                                           \n",
       "id26305  ThisDT processNN ,, howeverRB ,, affordedVBD m...   \n",
       "\n",
       "                                                  phrasing  \\\n",
       "id                                                           \n",
       "id26305  DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...   \n",
       "\n",
       "                                                lemmatized  \n",
       "id                                                          \n",
       "id26305  This process , however , afforded me no mean o...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#тоз лематизатор е мн мн зле\n",
    "explore_backup = explore.copy()\n",
    "explore_backup.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = explore['author']\n",
    "X = explore.drop(['text', 'author', 'preprocessed'], axis = 1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrasing</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...</td>\n",
       "      <td>This process , however , afforded me no mean o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>PRP RB RB VBD TO PRP IN DT NN MD VB DT JJ NN .</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN PR...</td>\n",
       "      <td>In his left hand wa a gold snuff box , from wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>WRB RB VBZ JJ IN PRP VBD IN NNP NNP IN DT JJ J...</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : C...</td>\n",
       "      <td>Finding nothing else , not even gold , the Sup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phrasing  \\\n",
       "id                                                           \n",
       "id26305  DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...   \n",
       "id17569     PRP RB RB VBD TO PRP IN DT NN MD VB DT JJ NN .   \n",
       "id11008  IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN PR...   \n",
       "id27763  WRB RB VBZ JJ IN PRP VBD IN NNP NNP IN DT JJ J...   \n",
       "id12958  VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : C...   \n",
       "\n",
       "                                                lemmatized  \n",
       "id                                                          \n",
       "id26305  This process , however , afforded me no mean o...  \n",
       "id17569  It never once occurred to me that the fumbling...  \n",
       "id11008  In his left hand wa a gold snuff box , from wh...  \n",
       "id27763  How lovely is spring As we looked from Windsor...  \n",
       "id12958  Finding nothing else , not even gold , the Sup...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305     Едгар\n",
       "id17569    Хауърд\n",
       "id11008     Едгар\n",
       "id27763      Мери\n",
       "id12958    Хауърд\n",
       "Name: author, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 19579)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X.lemmatized.value_counts()), sum(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в последващите опити съм използвал векторайзера подготвен за двете колони 'phrasing' и lemmatized',\n",
    "# само върху колонката 'preprocessed', защо така, ами объркал съм с какво тренирам, видях че съм в грешка,\n",
    "# но все пак ми подобрява скора реших да си поиграя малко с хиперпараметрите"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84742647  0.84845234  0.84030651]\n",
      "[-0.40515771 -0.39951364 -0.41681723]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "                                        ('phrasing',\n",
    "                                               TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range=(1, 2), \n",
    "                                                                \n",
    "                                                                lowercase=True)),\n",
    "                                        ('lemmatized',\n",
    "                                                TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range=(1, 2), \n",
    "                                                                lowercase=True)   \n",
    "                                                    )\n",
    "                                    ])),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8471201   0.84860558  0.83969349]\n",
      "[-0.40515177 -0.39943733 -0.41685359]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "                                        ('phrasing',\n",
    "                                               TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range=(1, 2),\n",
    "                                                                max_df=0.7,\n",
    "                                                                lowercase=True)),\n",
    "                                        ('lemmatized',\n",
    "                                                TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range=(1, 2), \n",
    "                                                                lowercase=True)   \n",
    "                                                    )\n",
    "                                    ])),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "def random_search():\n",
    "    params = {\n",
    "        \"clf__alpha\": [0.001, 0.01, 0.1, 0.5, 1, 2]\n",
    "    }\n",
    "    params_count_word = {\"features__phrasing__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "                      \"features__phrasing__analyzer\": ['word'],\n",
    "                      \"features__phrasing__max_df\":[1, 0.9, 0.8, 0.7, 0.6],\n",
    "                      \"features__phrasing__lowercase\": [False, True],\n",
    "                      \"features__lemmatized__ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "                      \"features__lemmatized__analyzer\": ['word'],\n",
    "                      \"features__lemmatized__max_df\":[0.8, 0.7, 0.6, 0.5, 0.4],\n",
    "                      \"features__lemmatized__lowercase\": [False, True] \n",
    "                        }\n",
    "                      \n",
    "    params.update(params_count_word)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "                                        ('phrasing',\n",
    "                                               TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                min_df = 0\n",
    "                                                                )),\n",
    "                                        ('lemmatized',\n",
    "                                                TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                \n",
    "                                                               )   \n",
    "                                                    )\n",
    "    ])),\n",
    "     ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=params, \n",
    "                                       scoring='neg_log_loss',\n",
    "                                       n_iter=20, cv=3, n_jobs=2)\n",
    "\n",
    "    random_search.fit(explore.preprocessed, explore.author)\n",
    "    report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: -0.403 (std: 0.007)\n",
      "Parameters: {'features__phrasing__analyzer': 'word', 'features__phrasing__lowercase': True, 'features__lemmatized__lowercase': False, 'features__lemmatized__analyzer': 'word', 'features__phrasing__max_df': 0.7, 'clf__alpha': 0.1, 'features__phrasing__ngram_range': (1, 2), 'features__lemmatized__max_df': 0.4, 'features__lemmatized__ngram_range': (1, 2)}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: -0.414 (std: 0.007)\n",
      "Parameters: {'features__phrasing__analyzer': 'word', 'features__phrasing__lowercase': True, 'features__lemmatized__lowercase': True, 'features__lemmatized__analyzer': 'word', 'features__phrasing__max_df': 0.8, 'clf__alpha': 0.1, 'features__phrasing__ngram_range': (1, 2), 'features__lemmatized__max_df': 0.4, 'features__lemmatized__ngram_range': (1, 3)}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: -0.430 (std: 0.008)\n",
      "Parameters: {'features__phrasing__analyzer': 'word', 'features__phrasing__lowercase': True, 'features__lemmatized__lowercase': True, 'features__lemmatized__analyzer': 'word', 'features__phrasing__max_df': 0.7, 'clf__alpha': 0.1, 'features__phrasing__ngram_range': (1, 3), 'features__lemmatized__max_df': 0.4, 'features__lemmatized__ngram_range': (1, 3)}\n",
      "\n",
      "Model with rank: 4\n",
      "Mean validation score: -0.436 (std: 0.006)\n",
      "Parameters: {'features__phrasing__analyzer': 'word', 'features__phrasing__lowercase': False, 'features__lemmatized__lowercase': True, 'features__lemmatized__analyzer': 'word', 'features__phrasing__max_df': 1, 'clf__alpha': 0.1, 'features__phrasing__ngram_range': (1, 3), 'features__lemmatized__max_df': 0.4, 'features__lemmatized__ngram_range': (1, 1)}\n",
      "\n",
      "Model with rank: 5\n",
      "Mean validation score: -0.456 (std: 0.001)\n",
      "Parameters: {'features__phrasing__analyzer': 'word', 'features__phrasing__lowercase': False, 'features__lemmatized__lowercase': False, 'features__lemmatized__analyzer': 'word', 'features__phrasing__max_df': 0.9, 'clf__alpha': 0.5, 'features__phrasing__ngram_range': (1, 1), 'features__lemmatized__max_df': 0.7, 'features__lemmatized__ngram_range': (1, 2)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85003064  0.85442844  0.84873563]\n",
      "[-0.37615715 -0.36891552 -0.38519335]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "                                        ('phrasing',\n",
    "                                               TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range= (1, 1),\n",
    "                                                                max_df=0.7,\n",
    "                                                                lowercase=False)),\n",
    "                                        ('lemmatized',\n",
    "                                                TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range=(1, 2), \n",
    "                                                                max_df=0.8,\n",
    "                                                                lowercase=False)   \n",
    "                                                    )\n",
    "                                    ])),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(pipeline, explore.preprocessed, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "еxplore_test = test.copy()\n",
    "еxplore_test['preprocessed'] = еxplore_test.text.apply(lambda s: \" \".join(\"%s%s\" % tup for tup in nltk.pos_tag(nltk.word_tokenize(s))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "      <td>StillRB ,, asIN IPRP urgedVBD ourPRP$ leavingV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "      <td>IfIN aDT fireNN wantedVBD fanningNN ,, itPRP c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "      <td>AndCC whenWRB theyPRP hadVBD brokenVBN downRP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "      <td>WhileIN IPRP wasVBD thinkingVBG howWRB IPRP sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "      <td>IPRP amVBP notRB sureJJ toTO whatWP limitVB hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "id                                                           \n",
       "id02310  Still, as I urged our leaving Ireland with suc...   \n",
       "id24541  If a fire wanted fanning, it could readily be ...   \n",
       "id00134  And when they had broken down the frail door t...   \n",
       "id27757  While I was thinking how I should possibly man...   \n",
       "id04081  I am not sure to what limit his knowledge may ...   \n",
       "\n",
       "                                              preprocessed  \n",
       "id                                                          \n",
       "id02310  StillRB ,, asIN IPRP urgedVBD ourPRP$ leavingV...  \n",
       "id24541  IfIN aDT fireNN wantedVBD fanningNN ,, itPRP c...  \n",
       "id00134  AndCC whenWRB theyPRP hadVBD brokenVBN downRP ...  \n",
       "id27757  WhileIN IPRP wasVBD thinkingVBG howWRB IPRP sh...  \n",
       "id04081  IPRP amVBP notRB sureJJ toTO whatWP limitVB hi...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "еxplore_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(explore.preprocessed, explore.author)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.287808</td>\n",
       "      <td>0.308698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.403494  0.287808  0.308698\n",
       "1  id24541  0.403494  0.287808  0.308698\n",
       "2  id00134  0.403494  0.287808  0.308698\n",
       "3  id27757  0.403494  0.287808  0.308698\n",
       "4  id04081  0.403494  0.287808  0.308698"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.zip\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.48665137e-02   9.84131310e-01   1.00217639e-03]\n",
      " [  9.95451318e-01   3.34141033e-04   4.21454143e-03]\n",
      " [  1.28009778e-01   3.33402095e-03   8.68656201e-01]\n",
      " [  8.86143678e-01   6.82360768e-04   1.13173961e-01]\n",
      " [  6.51794868e-01   9.29924042e-02   2.55212728e-01]\n",
      " [  9.82755645e-01   5.96227061e-04   1.66481277e-02]\n",
      " [  7.38770736e-01   1.43166442e-02   2.46912620e-01]\n",
      " [  1.75980023e-03   9.32070668e-01   6.61695322e-02]\n",
      " [  9.99056615e-01   2.36637610e-06   9.41018833e-04]\n",
      " [  9.32773166e-01   6.05444503e-02   6.68238390e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.predict_proba(еxplore_test[:10].preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pipeline.predict_proba(еxplore_test.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAP</th>\n",
       "      <th>MWS</th>\n",
       "      <th>HPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id02310</th>\n",
       "      <td>0.014867</td>\n",
       "      <td>0.984131</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24541</th>\n",
       "      <td>0.995451</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.004215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00134</th>\n",
       "      <td>0.128010</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.868656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27757</th>\n",
       "      <td>0.886144</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.113174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04081</th>\n",
       "      <td>0.651795</td>\n",
       "      <td>0.092992</td>\n",
       "      <td>0.255213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27337</th>\n",
       "      <td>0.982756</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.016648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id24265</th>\n",
       "      <td>0.738771</td>\n",
       "      <td>0.014317</td>\n",
       "      <td>0.246913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id25917</th>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>0.066170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04951</th>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14549</th>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.060544</td>\n",
       "      <td>0.006682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EAP       MWS       HPL\n",
       "id                                   \n",
       "id02310  0.014867  0.984131  0.001002\n",
       "id24541  0.995451  0.000334  0.004215\n",
       "id00134  0.128010  0.003334  0.868656\n",
       "id27757  0.886144  0.000682  0.113174\n",
       "id04081  0.651795  0.092992  0.255213\n",
       "id27337  0.982756  0.000596  0.016648\n",
       "id24265  0.738771  0.014317  0.246913\n",
       "id25917  0.001760  0.932071  0.066170\n",
       "id04951  0.999057  0.000002  0.000941\n",
       "id14549  0.932773  0.060544  0.006682"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file = pd.DataFrame(test_predictions, columns=['EAP', 'MWS', 'HPL'], index=test.index)\n",
    "submit_file.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_file.to_csv(\"submit_Tfidf_MNB_text.csv\") # тая работа здраво овърфитва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrasing</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...</td>\n",
       "      <td>This process , however , afforded me no mean o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>PRP RB RB VBD TO PRP IN DT NN MD VB DT JJ NN .</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN PR...</td>\n",
       "      <td>In his left hand wa a gold snuff box , from wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>WRB RB VBZ JJ IN PRP VBD IN NNP NNP IN DT JJ J...</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : C...</td>\n",
       "      <td>Finding nothing else , not even gold , the Sup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phrasing  \\\n",
       "id                                                           \n",
       "id26305  DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...   \n",
       "id17569     PRP RB RB VBD TO PRP IN DT NN MD VB DT JJ NN .   \n",
       "id11008  IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN PR...   \n",
       "id27763  WRB RB VBZ JJ IN PRP VBD IN NNP NNP IN DT JJ J...   \n",
       "id12958  VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : C...   \n",
       "\n",
       "                                                lemmatized  \n",
       "id                                                          \n",
       "id26305  This process , however , afforded me no mean o...  \n",
       "id17569  It never once occurred to me that the fumbling...  \n",
       "id11008  In his left hand wa a gold snuff box , from wh...  \n",
       "id27763  How lovely is spring As we looked from Windsor...  \n",
       "id12958  Finding nothing else , not even gold , the Sup...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ще се опитам да си подкарам featureUnion върху 'phrasing' и lemmatized', както исках да направя в началото\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FeatureUnion([\n",
    "                                        ('phrasing',\n",
    "                                               TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range=(1, 3), \n",
    "                                                                lowercase=True)),\n",
    "                                        ('lemmatized',\n",
    "                                                TfidfVectorizer(analyzer = 'word',\n",
    "                                                                stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                                                ngram_range=(1, 3), \n",
    "                                                                lowercase=True)   \n",
    "                                                    )\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_transformer.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(features) # тва няма как да е правилно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_features = TfidfVectorizer(analyzer = 'word',\n",
    "                                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                                    ngram_range=(1, 2), \n",
    "                                    min_df=2,\n",
    "                                    max_df=0.7,\n",
    "                                    lowercase=True).fit(explore_backup.preprocessed).transform(explore_backup.preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 70534)\t0.158736018024\n",
      "  (0, 70529)\t0.0923334212922\n",
      "  (0, 68896)\t0.168187004138\n",
      "  (0, 68893)\t0.141783362204\n",
      "  (0, 67001)\t0.114711097531\n",
      "  (0, 65382)\t0.16533500168\n",
      "  (0, 64157)\t0.0638805598688\n",
      "  (0, 63288)\t0.0335840395615\n",
      "  (0, 62176)\t0.181011193203\n",
      "  (0, 61936)\t0.0568797103537\n",
      "  (0, 60749)\t0.129714436942\n",
      "  (0, 59498)\t0.137803501823\n",
      "  (0, 57994)\t0.128233535273\n",
      "  (0, 52987)\t0.175688673843\n",
      "  (0, 52883)\t0.0705975625983\n",
      "  (0, 50909)\t0.175688673843\n",
      "  (0, 50908)\t0.151234348318\n",
      "  (0, 50493)\t0.168187004138\n",
      "  (0, 50462)\t0.0863211733545\n",
      "  (0, 48774)\t0.150040295713\n",
      "  (0, 48768)\t0.124105068519\n",
      "  (0, 46331)\t0.147861145367\n",
      "  (0, 45491)\t0.104554250565\n",
      "  (0, 44635)\t0.134530037086\n",
      "  (0, 43566)\t0.0896280233571\n",
      "  :\t:\n",
      "  (19578, 50494)\t0.143667917756\n",
      "  (19578, 50462)\t0.125868635276\n",
      "  (19578, 42693)\t0.164422828718\n",
      "  (19578, 42631)\t0.0849177880889\n",
      "  (19578, 40717)\t0.0414705748841\n",
      "  (19578, 39769)\t0.206740450946\n",
      "  (19578, 39752)\t0.0770419748578\n",
      "  (19578, 38282)\t0.237479747289\n",
      "  (19578, 37753)\t0.0704448543481\n",
      "  (19578, 36665)\t0.237479747289\n",
      "  (19578, 36191)\t0.172183824335\n",
      "  (19578, 36058)\t0.0829278007572\n",
      "  (19578, 32817)\t0.263940247482\n",
      "  (19578, 32816)\t0.224381871574\n",
      "  (19578, 31874)\t0.104627270385\n",
      "  (19578, 31781)\t0.188585968594\n",
      "  (19578, 31600)\t0.0697499362247\n",
      "  (19578, 26134)\t0.256179251865\n",
      "  (19578, 25954)\t0.0752931645399\n",
      "  (19578, 23534)\t0.245240742906\n",
      "  (19578, 12335)\t0.237479747289\n",
      "  (19578, 4297)\t0.163976906457\n",
      "  (19578, 3450)\t0.0423598056738\n",
      "  (19578, 3173)\t0.168807212801\n",
      "  (19578, 667)\t0.0529376547645\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['phrasing_features'] = TfidfVectorizer(analyzer = 'word',\n",
    "                    stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                    ngram_range=(1, 2), \n",
    "                    min_df = 0,\n",
    "                    max_df = 1,\n",
    "                    lowercase=True).fit(X.phrasing).transform(X.phrasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "id26305      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id17569      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id11008      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id27763      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id12958      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id22965      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id09674      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id13515      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id19322      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id00912      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id16737      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id16607      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id19764      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id18886      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id17189      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id12799      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id08441      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id13117      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id14862      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id20836      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id11411      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id08075      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id18925      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id19925      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id01704      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id10125      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id02448      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id23451      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id27907      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id08121      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "                                 ...                        \n",
      "id20955      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id01270      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id22290      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id20272      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id18082      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id07976      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id26741      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id26698      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id22265      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id14778      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id18823      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id00893      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id08678      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id10857      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id10563      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id11752      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id26214      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id00832      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id04187      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id22378      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id26790      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id14263      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id14420      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id03325      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id07567      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id17718      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id08973      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id05267      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id17513      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "id00393      (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...\n",
      "Name: phrasing_features, Length: 19579, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X['phrasing_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['lemmatized_features'] = TfidfVectorizer(analyzer = 'word',\n",
    "                       stop_words=nltk.corpus.stopwords.words('english'),\n",
    "                       ngram_range=(1, 2), \n",
    "                       max_df=0.8,\n",
    "                       lowercase=False).fit(X.lemmatized).transform(X.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "id26305      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id17569      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id11008      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id27763      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id12958      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id22965      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id09674      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id13515      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id19322      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id00912      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id16737      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id16607      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id19764      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id18886      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id17189      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id12799      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id08441      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id13117      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id14862      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id20836      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id11411      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id08075      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id18925      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id19925      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id01704      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id10125      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id02448      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id23451      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id27907      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id08121      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "                                 ...                        \n",
      "id20955      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id01270      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id22290      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id20272      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id18082      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id07976      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id26741      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id26698      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id22265      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id14778      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id18823      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id00893      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id08678      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id10857      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id10563      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id11752      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id26214      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id00832      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id04187      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id22378      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id26790      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id14263      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id14420      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id03325      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id07567      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id17718      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id08973      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id05267      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id17513      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "id00393      (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...\n",
      "Name: lemmatized_features, Length: 19579, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X['lemmatized_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrasing</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>phrasing_features</th>\n",
       "      <th>lemmatized_features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...</td>\n",
       "      <td>This process , however , afforded me no mean o...</td>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  phrasing  \\\n",
       "id                                                           \n",
       "id26305  DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...   \n",
       "\n",
       "                                                lemmatized  \\\n",
       "id                                                           \n",
       "id26305  This process , however , afforded me no mean o...   \n",
       "\n",
       "                                         phrasing_features  \\\n",
       "id                                                           \n",
       "id26305    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "\n",
       "                                       lemmatized_features  \n",
       "id                                                          \n",
       "id26305    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# направих ги ръчно щото featureUnion-а нещо не ме харесва\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrasing_features</th>\n",
       "      <th>lemmatized_features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22965</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09674</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13515</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19322</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00912</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16737</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id16607</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19764</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18886</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17189</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12799</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08441</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id13117</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14862</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id20836</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11411</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08075</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18925</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id19925</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01704</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10125</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id02448</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id23451</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27907</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08121</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id20955</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id01270</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22290</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id20272</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18082</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07976</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26741</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26698</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22265</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14778</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id18823</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00893</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08678</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10857</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id10563</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11752</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26214</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00832</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id04187</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id22378</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id26790</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14263</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id14420</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id03325</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id07567</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17718</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id08973</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id05267</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17513</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00393</th>\n",
       "      <td>(200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...</td>\n",
       "      <td>(0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19579 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         phrasing_features  \\\n",
       "id                                                           \n",
       "id26305    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id17569    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id11008    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id27763    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id12958    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id22965    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id09674    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id13515    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id19322    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id00912    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id16737    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id16607    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id19764    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id18886    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id17189    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id12799    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id08441    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id13117    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id14862    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id20836    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id11411    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id08075    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id18925    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id19925    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id01704    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id10125    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id02448    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id23451    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id27907    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id08121    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "...                                                    ...   \n",
       "id20955    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id01270    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id22290    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id20272    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id18082    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id07976    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id26741    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id26698    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id22265    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id14778    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id18823    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id00893    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id08678    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id10857    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id10563    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id11752    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id26214    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id00832    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id04187    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id22378    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id26790    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id14263    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id14420    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id03325    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id07567    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id17718    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id08973    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id05267    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id17513    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "id00393    (200, 0)\\t1.0\\n  (537, 56)\\t1.0\\n  (1074, 13...   \n",
       "\n",
       "                                       lemmatized_features  \n",
       "id                                                          \n",
       "id26305    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id17569    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id11008    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id27763    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id12958    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id22965    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id09674    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id13515    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id19322    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id00912    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id16737    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id16607    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id19764    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id18886    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id17189    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id12799    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id08441    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id13117    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id14862    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id20836    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id11411    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id08075    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id18925    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id19925    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id01704    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id10125    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id02448    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id23451    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id27907    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id08121    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "...                                                    ...  \n",
       "id20955    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id01270    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id22290    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id20272    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id18082    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id07976    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id26741    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id26698    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id22265    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id14778    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id18823    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id00893    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id08678    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id10857    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id10563    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id11752    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id26214    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id00832    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id04187    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id22378    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id26790    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id14263    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id14420    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id03325    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id07567    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id17718    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id08973    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id05267    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id17513    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "id00393    (0, 236421)\\t0.175727022943\\n  (0, 236391)\\t...  \n",
       "\n",
       "[19579 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = MultinomialNB(alpha=0.1)\n",
    "X.drop(['phrasing','lemmatized'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB.fit(X, y)\n",
    "# не става..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ще се опитвам да варя някакви статистики от текста..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>phrasing</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>Едгар</td>\n",
       "      <td>ThisDT processNN ,, howeverRB ,, affordedVBD m...</td>\n",
       "      <td>DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...</td>\n",
       "      <td>This process , however , afforded me no mean o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>Хауърд</td>\n",
       "      <td>ItPRP neverRB onceRB occurredVBD toTO mePRP th...</td>\n",
       "      <td>PRP RB RB VBD TO PRP IN DT NN MD VB DT JJ NN .</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>Едгар</td>\n",
       "      <td>InIN hisPRP$ leftJJ handNN wasVBD aDT goldJJ s...</td>\n",
       "      <td>IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN PR...</td>\n",
       "      <td>In his left hand wa a gold snuff box , from wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>Мери</td>\n",
       "      <td>HowWRB lovelyRB isVBZ springJJ AsIN wePRP look...</td>\n",
       "      <td>WRB RB VBZ JJ IN PRP VBD IN NNP NNP IN DT JJ J...</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>Хауърд</td>\n",
       "      <td>FindingVBG nothingNN elseRB ,, notRB evenRB go...</td>\n",
       "      <td>VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : C...</td>\n",
       "      <td>Finding nothing else , not even gold , the Sup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  author  \\\n",
       "id                                                                   \n",
       "id26305  This process, however, afforded me no means of...   Едгар   \n",
       "id17569  It never once occurred to me that the fumbling...  Хауърд   \n",
       "id11008  In his left hand was a gold snuff box, from wh...   Едгар   \n",
       "id27763  How lovely is spring As we looked from Windsor...    Мери   \n",
       "id12958  Finding nothing else, not even gold, the Super...  Хауърд   \n",
       "\n",
       "                                              preprocessed  \\\n",
       "id                                                           \n",
       "id26305  ThisDT processNN ,, howeverRB ,, affordedVBD m...   \n",
       "id17569  ItPRP neverRB onceRB occurredVBD toTO mePRP th...   \n",
       "id11008  InIN hisPRP$ leftJJ handNN wasVBD aDT goldJJ s...   \n",
       "id27763  HowWRB lovelyRB isVBZ springJJ AsIN wePRP look...   \n",
       "id12958  FindingVBG nothingNN elseRB ,, notRB evenRB go...   \n",
       "\n",
       "                                                  phrasing  \\\n",
       "id                                                           \n",
       "id26305  DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN P...   \n",
       "id17569     PRP RB RB VBD TO PRP IN DT NN MD VB DT JJ NN .   \n",
       "id11008  IN PRP$ JJ NN VBD DT JJ NN NN , IN WDT , IN PR...   \n",
       "id27763  WRB RB VBZ JJ IN PRP VBD IN NNP NNP IN DT JJ J...   \n",
       "id12958  VBG NN RB , RB RB NN , DT NNP VBD PRP$ NNS : C...   \n",
       "\n",
       "                                                lemmatized  \n",
       "id                                                          \n",
       "id26305  This process , however , afforded me no mean o...  \n",
       "id17569  It never once occurred to me that the fumbling...  \n",
       "id11008  In his left hand wa a gold snuff box , from wh...  \n",
       "id27763  How lovely is spring As we looked from Windsor...  \n",
       "id12958  Finding nothing else , not even gold , the Sup...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore = explore_backup.copy()\n",
    "explore.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore['punctuation_count'] = explore.phrasing.apply(lambda s: s.count(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305    4\n",
       "id17569    0\n",
       "id11008    4\n",
       "id27763    3\n",
       "id12958    2\n",
       "id22965    4\n",
       "id09674    3\n",
       "id13515    0\n",
       "id19322    7\n",
       "id00912    2\n",
       "Name: punctuation_count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore.punctuation_count.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = explore.author\n",
    "X = explore.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(X.phrasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cc': 0,\n",
       " 'cc cc': 1,\n",
       " 'cc cd': 2,\n",
       " 'cc dt': 3,\n",
       " 'cc ex': 4,\n",
       " 'cc fw': 5,\n",
       " 'cc in': 6,\n",
       " 'cc jj': 7,\n",
       " 'cc jjr': 8,\n",
       " 'cc jjs': 9,\n",
       " 'cc md': 10,\n",
       " 'cc nn': 11,\n",
       " 'cc nnp': 12,\n",
       " 'cc nnps': 13,\n",
       " 'cc nns': 14,\n",
       " 'cc pdt': 15,\n",
       " 'cc pos': 16,\n",
       " 'cc prp': 17,\n",
       " 'cc rb': 18,\n",
       " 'cc rbr': 19,\n",
       " 'cc rbs': 20,\n",
       " 'cc to': 21,\n",
       " 'cc uh': 22,\n",
       " 'cc vb': 23,\n",
       " 'cc vbd': 24,\n",
       " 'cc vbg': 25,\n",
       " 'cc vbn': 26,\n",
       " 'cc vbp': 27,\n",
       " 'cc vbz': 28,\n",
       " 'cc wdt': 29,\n",
       " 'cc wp': 30,\n",
       " 'cc wrb': 31,\n",
       " 'cd': 32,\n",
       " 'cd cc': 33,\n",
       " 'cd cd': 34,\n",
       " 'cd dt': 35,\n",
       " 'cd ex': 36,\n",
       " 'cd in': 37,\n",
       " 'cd jj': 38,\n",
       " 'cd jjr': 39,\n",
       " 'cd jjs': 40,\n",
       " 'cd md': 41,\n",
       " 'cd nn': 42,\n",
       " 'cd nnp': 43,\n",
       " 'cd nns': 44,\n",
       " 'cd pdt': 45,\n",
       " 'cd pos': 46,\n",
       " 'cd prp': 47,\n",
       " 'cd rb': 48,\n",
       " 'cd to': 49,\n",
       " 'cd vb': 50,\n",
       " 'cd vbd': 51,\n",
       " 'cd vbg': 52,\n",
       " 'cd vbn': 53,\n",
       " 'cd vbp': 54,\n",
       " 'cd vbz': 55,\n",
       " 'cd wdt': 56,\n",
       " 'cd wp': 57,\n",
       " 'cd wrb': 58,\n",
       " 'dt': 59,\n",
       " 'dt cc': 60,\n",
       " 'dt cd': 61,\n",
       " 'dt dt': 62,\n",
       " 'dt ex': 63,\n",
       " 'dt fw': 64,\n",
       " 'dt in': 65,\n",
       " 'dt jj': 66,\n",
       " 'dt jjr': 67,\n",
       " 'dt jjs': 68,\n",
       " 'dt md': 69,\n",
       " 'dt nn': 70,\n",
       " 'dt nnp': 71,\n",
       " 'dt nnps': 72,\n",
       " 'dt nns': 73,\n",
       " 'dt pdt': 74,\n",
       " 'dt pos': 75,\n",
       " 'dt prp': 76,\n",
       " 'dt rb': 77,\n",
       " 'dt rbr': 78,\n",
       " 'dt rbs': 79,\n",
       " 'dt rp': 80,\n",
       " 'dt to': 81,\n",
       " 'dt uh': 82,\n",
       " 'dt vb': 83,\n",
       " 'dt vbd': 84,\n",
       " 'dt vbg': 85,\n",
       " 'dt vbn': 86,\n",
       " 'dt vbp': 87,\n",
       " 'dt vbz': 88,\n",
       " 'dt wdt': 89,\n",
       " 'dt wp': 90,\n",
       " 'dt wrb': 91,\n",
       " 'ex': 92,\n",
       " 'ex cc': 93,\n",
       " 'ex cd': 94,\n",
       " 'ex dt': 95,\n",
       " 'ex in': 96,\n",
       " 'ex jj': 97,\n",
       " 'ex md': 98,\n",
       " 'ex nn': 99,\n",
       " 'ex nnp': 100,\n",
       " 'ex nns': 101,\n",
       " 'ex pos': 102,\n",
       " 'ex prp': 103,\n",
       " 'ex rb': 104,\n",
       " 'ex to': 105,\n",
       " 'ex vb': 106,\n",
       " 'ex vbd': 107,\n",
       " 'ex vbg': 108,\n",
       " 'ex vbn': 109,\n",
       " 'ex vbp': 110,\n",
       " 'ex vbz': 111,\n",
       " 'ex wrb': 112,\n",
       " 'fw': 113,\n",
       " 'fw cc': 114,\n",
       " 'fw cd': 115,\n",
       " 'fw dt': 116,\n",
       " 'fw fw': 117,\n",
       " 'fw in': 118,\n",
       " 'fw jj': 119,\n",
       " 'fw jjr': 120,\n",
       " 'fw md': 121,\n",
       " 'fw nn': 122,\n",
       " 'fw nnp': 123,\n",
       " 'fw nns': 124,\n",
       " 'fw pos': 125,\n",
       " 'fw prp': 126,\n",
       " 'fw rb': 127,\n",
       " 'fw rp': 128,\n",
       " 'fw to': 129,\n",
       " 'fw vb': 130,\n",
       " 'fw vbd': 131,\n",
       " 'fw vbg': 132,\n",
       " 'fw vbn': 133,\n",
       " 'fw vbp': 134,\n",
       " 'fw vbz': 135,\n",
       " 'fw wdt': 136,\n",
       " 'fw wp': 137,\n",
       " 'fw wrb': 138,\n",
       " 'in': 139,\n",
       " 'in cc': 140,\n",
       " 'in cd': 141,\n",
       " 'in dt': 142,\n",
       " 'in ex': 143,\n",
       " 'in fw': 144,\n",
       " 'in in': 145,\n",
       " 'in jj': 146,\n",
       " 'in jjr': 147,\n",
       " 'in jjs': 148,\n",
       " 'in md': 149,\n",
       " 'in nn': 150,\n",
       " 'in nnp': 151,\n",
       " 'in nnps': 152,\n",
       " 'in nns': 153,\n",
       " 'in pdt': 154,\n",
       " 'in pos': 155,\n",
       " 'in prp': 156,\n",
       " 'in rb': 157,\n",
       " 'in rbr': 158,\n",
       " 'in rbs': 159,\n",
       " 'in rp': 160,\n",
       " 'in to': 161,\n",
       " 'in uh': 162,\n",
       " 'in vb': 163,\n",
       " 'in vbd': 164,\n",
       " 'in vbg': 165,\n",
       " 'in vbn': 166,\n",
       " 'in vbp': 167,\n",
       " 'in vbz': 168,\n",
       " 'in wdt': 169,\n",
       " 'in wp': 170,\n",
       " 'in wrb': 171,\n",
       " 'jj': 172,\n",
       " 'jj cc': 173,\n",
       " 'jj cd': 174,\n",
       " 'jj dt': 175,\n",
       " 'jj ex': 176,\n",
       " 'jj fw': 177,\n",
       " 'jj in': 178,\n",
       " 'jj jj': 179,\n",
       " 'jj jjr': 180,\n",
       " 'jj jjs': 181,\n",
       " 'jj md': 182,\n",
       " 'jj nn': 183,\n",
       " 'jj nnp': 184,\n",
       " 'jj nnps': 185,\n",
       " 'jj nns': 186,\n",
       " 'jj pdt': 187,\n",
       " 'jj pos': 188,\n",
       " 'jj prp': 189,\n",
       " 'jj rb': 190,\n",
       " 'jj rbr': 191,\n",
       " 'jj rbs': 192,\n",
       " 'jj rp': 193,\n",
       " 'jj to': 194,\n",
       " 'jj uh': 195,\n",
       " 'jj vb': 196,\n",
       " 'jj vbd': 197,\n",
       " 'jj vbg': 198,\n",
       " 'jj vbn': 199,\n",
       " 'jj vbp': 200,\n",
       " 'jj vbz': 201,\n",
       " 'jj wdt': 202,\n",
       " 'jj wp': 203,\n",
       " 'jj wrb': 204,\n",
       " 'jjr': 205,\n",
       " 'jjr cc': 206,\n",
       " 'jjr cd': 207,\n",
       " 'jjr dt': 208,\n",
       " 'jjr ex': 209,\n",
       " 'jjr in': 210,\n",
       " 'jjr jj': 211,\n",
       " 'jjr jjr': 212,\n",
       " 'jjr md': 213,\n",
       " 'jjr nn': 214,\n",
       " 'jjr nnp': 215,\n",
       " 'jjr nns': 216,\n",
       " 'jjr prp': 217,\n",
       " 'jjr rb': 218,\n",
       " 'jjr rbr': 219,\n",
       " 'jjr rp': 220,\n",
       " 'jjr to': 221,\n",
       " 'jjr vb': 222,\n",
       " 'jjr vbd': 223,\n",
       " 'jjr vbg': 224,\n",
       " 'jjr vbn': 225,\n",
       " 'jjr vbp': 226,\n",
       " 'jjr vbz': 227,\n",
       " 'jjr wdt': 228,\n",
       " 'jjr wp': 229,\n",
       " 'jjr wrb': 230,\n",
       " 'jjs': 231,\n",
       " 'jjs cc': 232,\n",
       " 'jjs cd': 233,\n",
       " 'jjs dt': 234,\n",
       " 'jjs ex': 235,\n",
       " 'jjs fw': 236,\n",
       " 'jjs in': 237,\n",
       " 'jjs jj': 238,\n",
       " 'jjs jjs': 239,\n",
       " 'jjs md': 240,\n",
       " 'jjs nn': 241,\n",
       " 'jjs nnp': 242,\n",
       " 'jjs nnps': 243,\n",
       " 'jjs nns': 244,\n",
       " 'jjs pdt': 245,\n",
       " 'jjs prp': 246,\n",
       " 'jjs rb': 247,\n",
       " 'jjs rbr': 248,\n",
       " 'jjs to': 249,\n",
       " 'jjs vb': 250,\n",
       " 'jjs vbd': 251,\n",
       " 'jjs vbg': 252,\n",
       " 'jjs vbn': 253,\n",
       " 'jjs vbp': 254,\n",
       " 'jjs vbz': 255,\n",
       " 'jjs wdt': 256,\n",
       " 'jjs wp': 257,\n",
       " 'jjs wrb': 258,\n",
       " 'md': 259,\n",
       " 'md cc': 260,\n",
       " 'md cd': 261,\n",
       " 'md dt': 262,\n",
       " 'md ex': 263,\n",
       " 'md in': 264,\n",
       " 'md jj': 265,\n",
       " 'md md': 266,\n",
       " 'md nn': 267,\n",
       " 'md nnp': 268,\n",
       " 'md nns': 269,\n",
       " 'md prp': 270,\n",
       " 'md rb': 271,\n",
       " 'md rbr': 272,\n",
       " 'md rbs': 273,\n",
       " 'md to': 274,\n",
       " 'md vb': 275,\n",
       " 'md vbd': 276,\n",
       " 'md vbg': 277,\n",
       " 'md vbn': 278,\n",
       " 'md vbz': 279,\n",
       " 'md wdt': 280,\n",
       " 'md wrb': 281,\n",
       " 'nn': 282,\n",
       " 'nn cc': 283,\n",
       " 'nn cd': 284,\n",
       " 'nn dt': 285,\n",
       " 'nn ex': 286,\n",
       " 'nn fw': 287,\n",
       " 'nn in': 288,\n",
       " 'nn jj': 289,\n",
       " 'nn jjr': 290,\n",
       " 'nn jjs': 291,\n",
       " 'nn md': 292,\n",
       " 'nn nn': 293,\n",
       " 'nn nnp': 294,\n",
       " 'nn nnps': 295,\n",
       " 'nn nns': 296,\n",
       " 'nn pdt': 297,\n",
       " 'nn pos': 298,\n",
       " 'nn prp': 299,\n",
       " 'nn rb': 300,\n",
       " 'nn rbr': 301,\n",
       " 'nn rbs': 302,\n",
       " 'nn rp': 303,\n",
       " 'nn to': 304,\n",
       " 'nn uh': 305,\n",
       " 'nn vb': 306,\n",
       " 'nn vbd': 307,\n",
       " 'nn vbg': 308,\n",
       " 'nn vbn': 309,\n",
       " 'nn vbp': 310,\n",
       " 'nn vbz': 311,\n",
       " 'nn wdt': 312,\n",
       " 'nn wp': 313,\n",
       " 'nn wrb': 314,\n",
       " 'nnp': 315,\n",
       " 'nnp cc': 316,\n",
       " 'nnp cd': 317,\n",
       " 'nnp dt': 318,\n",
       " 'nnp ex': 319,\n",
       " 'nnp fw': 320,\n",
       " 'nnp in': 321,\n",
       " 'nnp jj': 322,\n",
       " 'nnp jjr': 323,\n",
       " 'nnp jjs': 324,\n",
       " 'nnp md': 325,\n",
       " 'nnp nn': 326,\n",
       " 'nnp nnp': 327,\n",
       " 'nnp nnps': 328,\n",
       " 'nnp nns': 329,\n",
       " 'nnp pdt': 330,\n",
       " 'nnp pos': 331,\n",
       " 'nnp prp': 332,\n",
       " 'nnp rb': 333,\n",
       " 'nnp rbr': 334,\n",
       " 'nnp rbs': 335,\n",
       " 'nnp rp': 336,\n",
       " 'nnp to': 337,\n",
       " 'nnp uh': 338,\n",
       " 'nnp vb': 339,\n",
       " 'nnp vbd': 340,\n",
       " 'nnp vbg': 341,\n",
       " 'nnp vbn': 342,\n",
       " 'nnp vbp': 343,\n",
       " 'nnp vbz': 344,\n",
       " 'nnp wdt': 345,\n",
       " 'nnp wp': 346,\n",
       " 'nnp wrb': 347,\n",
       " 'nnps': 348,\n",
       " 'nnps cc': 349,\n",
       " 'nnps cd': 350,\n",
       " 'nnps dt': 351,\n",
       " 'nnps in': 352,\n",
       " 'nnps md': 353,\n",
       " 'nnps nn': 354,\n",
       " 'nnps nnp': 355,\n",
       " 'nnps pos': 356,\n",
       " 'nnps prp': 357,\n",
       " 'nnps rb': 358,\n",
       " 'nnps to': 359,\n",
       " 'nnps vb': 360,\n",
       " 'nnps vbd': 361,\n",
       " 'nnps vbg': 362,\n",
       " 'nnps vbp': 363,\n",
       " 'nnps wp': 364,\n",
       " 'nns': 365,\n",
       " 'nns cc': 366,\n",
       " 'nns cd': 367,\n",
       " 'nns dt': 368,\n",
       " 'nns ex': 369,\n",
       " 'nns fw': 370,\n",
       " 'nns in': 371,\n",
       " 'nns jj': 372,\n",
       " 'nns jjr': 373,\n",
       " 'nns jjs': 374,\n",
       " 'nns md': 375,\n",
       " 'nns nn': 376,\n",
       " 'nns nnp': 377,\n",
       " 'nns nnps': 378,\n",
       " 'nns nns': 379,\n",
       " 'nns pdt': 380,\n",
       " 'nns pos': 381,\n",
       " 'nns prp': 382,\n",
       " 'nns rb': 383,\n",
       " 'nns rbr': 384,\n",
       " 'nns rbs': 385,\n",
       " 'nns rp': 386,\n",
       " 'nns to': 387,\n",
       " 'nns uh': 388,\n",
       " 'nns vb': 389,\n",
       " 'nns vbd': 390,\n",
       " 'nns vbg': 391,\n",
       " 'nns vbn': 392,\n",
       " 'nns vbp': 393,\n",
       " 'nns vbz': 394,\n",
       " 'nns wdt': 395,\n",
       " 'nns wp': 396,\n",
       " 'nns wrb': 397,\n",
       " 'pdt': 398,\n",
       " 'pdt dt': 399,\n",
       " 'pdt in': 400,\n",
       " 'pdt jj': 401,\n",
       " 'pdt nn': 402,\n",
       " 'pdt prp': 403,\n",
       " 'pdt wdt': 404,\n",
       " 'pos': 405,\n",
       " 'pos cc': 406,\n",
       " 'pos cd': 407,\n",
       " 'pos dt': 408,\n",
       " 'pos in': 409,\n",
       " 'pos jj': 410,\n",
       " 'pos jjr': 411,\n",
       " 'pos jjs': 412,\n",
       " 'pos md': 413,\n",
       " 'pos nn': 414,\n",
       " 'pos nnp': 415,\n",
       " 'pos nns': 416,\n",
       " 'pos pdt': 417,\n",
       " 'pos pos': 418,\n",
       " 'pos prp': 419,\n",
       " 'pos rb': 420,\n",
       " 'pos rbr': 421,\n",
       " 'pos rbs': 422,\n",
       " 'pos rp': 423,\n",
       " 'pos to': 424,\n",
       " 'pos vb': 425,\n",
       " 'pos vbd': 426,\n",
       " 'pos vbg': 427,\n",
       " 'pos vbn': 428,\n",
       " 'pos vbp': 429,\n",
       " 'pos vbz': 430,\n",
       " 'pos wdt': 431,\n",
       " 'pos wp': 432,\n",
       " 'pos wrb': 433,\n",
       " 'prp': 434,\n",
       " 'prp cc': 435,\n",
       " 'prp cd': 436,\n",
       " 'prp dt': 437,\n",
       " 'prp ex': 438,\n",
       " 'prp fw': 439,\n",
       " 'prp in': 440,\n",
       " 'prp jj': 441,\n",
       " 'prp jjr': 442,\n",
       " 'prp jjs': 443,\n",
       " 'prp md': 444,\n",
       " 'prp nn': 445,\n",
       " 'prp nnp': 446,\n",
       " 'prp nnps': 447,\n",
       " 'prp nns': 448,\n",
       " 'prp pdt': 449,\n",
       " 'prp pos': 450,\n",
       " 'prp prp': 451,\n",
       " 'prp rb': 452,\n",
       " 'prp rbr': 453,\n",
       " 'prp rbs': 454,\n",
       " 'prp rp': 455,\n",
       " 'prp to': 456,\n",
       " 'prp uh': 457,\n",
       " 'prp vb': 458,\n",
       " 'prp vbd': 459,\n",
       " 'prp vbg': 460,\n",
       " 'prp vbn': 461,\n",
       " 'prp vbp': 462,\n",
       " 'prp vbz': 463,\n",
       " 'prp wdt': 464,\n",
       " 'prp wp': 465,\n",
       " 'prp wrb': 466,\n",
       " 'rb': 467,\n",
       " 'rb cc': 468,\n",
       " 'rb cd': 469,\n",
       " 'rb dt': 470,\n",
       " 'rb ex': 471,\n",
       " 'rb fw': 472,\n",
       " 'rb in': 473,\n",
       " 'rb jj': 474,\n",
       " 'rb jjr': 475,\n",
       " 'rb jjs': 476,\n",
       " 'rb md': 477,\n",
       " 'rb nn': 478,\n",
       " 'rb nnp': 479,\n",
       " 'rb nnps': 480,\n",
       " 'rb nns': 481,\n",
       " 'rb pdt': 482,\n",
       " 'rb pos': 483,\n",
       " 'rb prp': 484,\n",
       " 'rb rb': 485,\n",
       " 'rb rbr': 486,\n",
       " 'rb rbs': 487,\n",
       " 'rb rp': 488,\n",
       " 'rb to': 489,\n",
       " 'rb uh': 490,\n",
       " 'rb vb': 491,\n",
       " 'rb vbd': 492,\n",
       " 'rb vbg': 493,\n",
       " 'rb vbn': 494,\n",
       " 'rb vbp': 495,\n",
       " 'rb vbz': 496,\n",
       " 'rb wdt': 497,\n",
       " 'rb wp': 498,\n",
       " 'rb wrb': 499,\n",
       " 'rbr': 500,\n",
       " 'rbr cc': 501,\n",
       " 'rbr cd': 502,\n",
       " 'rbr dt': 503,\n",
       " 'rbr ex': 504,\n",
       " 'rbr fw': 505,\n",
       " 'rbr in': 506,\n",
       " 'rbr jj': 507,\n",
       " 'rbr md': 508,\n",
       " 'rbr nn': 509,\n",
       " 'rbr nnp': 510,\n",
       " 'rbr nns': 511,\n",
       " 'rbr prp': 512,\n",
       " 'rbr rb': 513,\n",
       " 'rbr to': 514,\n",
       " 'rbr vb': 515,\n",
       " 'rbr vbd': 516,\n",
       " 'rbr vbg': 517,\n",
       " 'rbr vbn': 518,\n",
       " 'rbr vbp': 519,\n",
       " 'rbr vbz': 520,\n",
       " 'rbs': 521,\n",
       " 'rbs cc': 522,\n",
       " 'rbs cd': 523,\n",
       " 'rbs dt': 524,\n",
       " 'rbs in': 525,\n",
       " 'rbs jj': 526,\n",
       " 'rbs nn': 527,\n",
       " 'rbs nns': 528,\n",
       " 'rbs rb': 529,\n",
       " 'rbs to': 530,\n",
       " 'rbs vbd': 531,\n",
       " 'rbs vbn': 532,\n",
       " 'rbs vbp': 533,\n",
       " 'rbs vbz': 534,\n",
       " 'rp': 535,\n",
       " 'rp cc': 536,\n",
       " 'rp cd': 537,\n",
       " 'rp dt': 538,\n",
       " 'rp fw': 539,\n",
       " 'rp in': 540,\n",
       " 'rp jj': 541,\n",
       " 'rp jjr': 542,\n",
       " 'rp jjs': 543,\n",
       " 'rp md': 544,\n",
       " 'rp nn': 545,\n",
       " 'rp nnp': 546,\n",
       " 'rp nns': 547,\n",
       " 'rp pdt': 548,\n",
       " 'rp prp': 549,\n",
       " 'rp rb': 550,\n",
       " 'rp rp': 551,\n",
       " 'rp to': 552,\n",
       " 'rp vb': 553,\n",
       " 'rp vbd': 554,\n",
       " 'rp vbg': 555,\n",
       " 'rp vbn': 556,\n",
       " 'rp vbp': 557,\n",
       " 'rp vbz': 558,\n",
       " 'rp wdt': 559,\n",
       " 'rp wp': 560,\n",
       " 'rp wrb': 561,\n",
       " 'to': 562,\n",
       " 'to cc': 563,\n",
       " 'to cd': 564,\n",
       " 'to dt': 565,\n",
       " 'to in': 566,\n",
       " 'to jj': 567,\n",
       " 'to jjr': 568,\n",
       " 'to jjs': 569,\n",
       " 'to nn': 570,\n",
       " 'to nnp': 571,\n",
       " 'to nnps': 572,\n",
       " 'to nns': 573,\n",
       " 'to pdt': 574,\n",
       " 'to prp': 575,\n",
       " 'to rb': 576,\n",
       " 'to rbr': 577,\n",
       " 'to rp': 578,\n",
       " 'to vb': 579,\n",
       " 'to vbd': 580,\n",
       " 'to vbg': 581,\n",
       " 'to vbn': 582,\n",
       " 'to vbp': 583,\n",
       " 'to wdt': 584,\n",
       " 'to wp': 585,\n",
       " 'to wrb': 586,\n",
       " 'uh': 587,\n",
       " 'uh cc': 588,\n",
       " 'uh dt': 589,\n",
       " 'uh ex': 590,\n",
       " 'uh fw': 591,\n",
       " 'uh in': 592,\n",
       " 'uh jj': 593,\n",
       " 'uh jjs': 594,\n",
       " 'uh nn': 595,\n",
       " 'uh nnp': 596,\n",
       " 'uh nns': 597,\n",
       " 'uh prp': 598,\n",
       " 'uh rb': 599,\n",
       " 'uh to': 600,\n",
       " 'uh uh': 601,\n",
       " 'uh vb': 602,\n",
       " 'uh vbd': 603,\n",
       " 'uh vbg': 604,\n",
       " 'uh vbn': 605,\n",
       " 'uh vbp': 606,\n",
       " 'uh wdt': 607,\n",
       " 'uh wp': 608,\n",
       " 'uh wrb': 609,\n",
       " 'vb': 610,\n",
       " 'vb cc': 611,\n",
       " 'vb cd': 612,\n",
       " 'vb dt': 613,\n",
       " 'vb ex': 614,\n",
       " 'vb fw': 615,\n",
       " 'vb in': 616,\n",
       " 'vb jj': 617,\n",
       " 'vb jjr': 618,\n",
       " 'vb jjs': 619,\n",
       " 'vb md': 620,\n",
       " 'vb nn': 621,\n",
       " 'vb nnp': 622,\n",
       " 'vb nnps': 623,\n",
       " 'vb nns': 624,\n",
       " 'vb pdt': 625,\n",
       " 'vb pos': 626,\n",
       " 'vb prp': 627,\n",
       " 'vb rb': 628,\n",
       " 'vb rbr': 629,\n",
       " 'vb rbs': 630,\n",
       " 'vb rp': 631,\n",
       " 'vb to': 632,\n",
       " 'vb uh': 633,\n",
       " 'vb vb': 634,\n",
       " 'vb vbd': 635,\n",
       " 'vb vbg': 636,\n",
       " 'vb vbn': 637,\n",
       " 'vb vbp': 638,\n",
       " 'vb vbz': 639,\n",
       " 'vb wdt': 640,\n",
       " 'vb wp': 641,\n",
       " 'vb wrb': 642,\n",
       " 'vbd': 643,\n",
       " 'vbd cc': 644,\n",
       " 'vbd cd': 645,\n",
       " 'vbd dt': 646,\n",
       " 'vbd ex': 647,\n",
       " 'vbd fw': 648,\n",
       " 'vbd in': 649,\n",
       " 'vbd jj': 650,\n",
       " 'vbd jjr': 651,\n",
       " 'vbd jjs': 652,\n",
       " 'vbd md': 653,\n",
       " 'vbd nn': 654,\n",
       " 'vbd nnp': 655,\n",
       " 'vbd nnps': 656,\n",
       " 'vbd nns': 657,\n",
       " 'vbd pdt': 658,\n",
       " 'vbd prp': 659,\n",
       " 'vbd rb': 660,\n",
       " 'vbd rbr': 661,\n",
       " 'vbd rbs': 662,\n",
       " 'vbd rp': 663,\n",
       " 'vbd to': 664,\n",
       " 'vbd uh': 665,\n",
       " 'vbd vb': 666,\n",
       " 'vbd vbd': 667,\n",
       " 'vbd vbg': 668,\n",
       " 'vbd vbn': 669,\n",
       " 'vbd vbp': 670,\n",
       " 'vbd vbz': 671,\n",
       " 'vbd wdt': 672,\n",
       " 'vbd wp': 673,\n",
       " 'vbd wrb': 674,\n",
       " 'vbg': 675,\n",
       " 'vbg cc': 676,\n",
       " 'vbg cd': 677,\n",
       " 'vbg dt': 678,\n",
       " 'vbg ex': 679,\n",
       " 'vbg in': 680,\n",
       " 'vbg jj': 681,\n",
       " 'vbg jjr': 682,\n",
       " 'vbg jjs': 683,\n",
       " 'vbg md': 684,\n",
       " 'vbg nn': 685,\n",
       " 'vbg nnp': 686,\n",
       " 'vbg nns': 687,\n",
       " 'vbg pdt': 688,\n",
       " 'vbg prp': 689,\n",
       " 'vbg rb': 690,\n",
       " 'vbg rbr': 691,\n",
       " 'vbg rp': 692,\n",
       " 'vbg to': 693,\n",
       " 'vbg uh': 694,\n",
       " 'vbg vb': 695,\n",
       " 'vbg vbd': 696,\n",
       " 'vbg vbg': 697,\n",
       " 'vbg vbn': 698,\n",
       " 'vbg vbp': 699,\n",
       " 'vbg vbz': 700,\n",
       " 'vbg wdt': 701,\n",
       " 'vbg wp': 702,\n",
       " 'vbg wrb': 703,\n",
       " 'vbn': 704,\n",
       " 'vbn cc': 705,\n",
       " 'vbn cd': 706,\n",
       " 'vbn dt': 707,\n",
       " 'vbn ex': 708,\n",
       " 'vbn fw': 709,\n",
       " 'vbn in': 710,\n",
       " 'vbn jj': 711,\n",
       " 'vbn jjr': 712,\n",
       " 'vbn jjs': 713,\n",
       " 'vbn md': 714,\n",
       " 'vbn nn': 715,\n",
       " 'vbn nnp': 716,\n",
       " 'vbn nnps': 717,\n",
       " 'vbn nns': 718,\n",
       " 'vbn pdt': 719,\n",
       " 'vbn pos': 720,\n",
       " 'vbn prp': 721,\n",
       " 'vbn rb': 722,\n",
       " 'vbn rbr': 723,\n",
       " 'vbn rbs': 724,\n",
       " 'vbn rp': 725,\n",
       " 'vbn to': 726,\n",
       " 'vbn uh': 727,\n",
       " 'vbn vb': 728,\n",
       " 'vbn vbd': 729,\n",
       " 'vbn vbg': 730,\n",
       " 'vbn vbn': 731,\n",
       " 'vbn vbp': 732,\n",
       " 'vbn vbz': 733,\n",
       " 'vbn wdt': 734,\n",
       " 'vbn wp': 735,\n",
       " 'vbn wrb': 736,\n",
       " 'vbp': 737,\n",
       " 'vbp cc': 738,\n",
       " 'vbp cd': 739,\n",
       " 'vbp dt': 740,\n",
       " 'vbp ex': 741,\n",
       " 'vbp fw': 742,\n",
       " 'vbp in': 743,\n",
       " 'vbp jj': 744,\n",
       " 'vbp jjr': 745,\n",
       " 'vbp jjs': 746,\n",
       " 'vbp md': 747,\n",
       " 'vbp nn': 748,\n",
       " 'vbp nnp': 749,\n",
       " 'vbp nns': 750,\n",
       " 'vbp pdt': 751,\n",
       " 'vbp pos': 752,\n",
       " 'vbp prp': 753,\n",
       " 'vbp rb': 754,\n",
       " 'vbp rbr': 755,\n",
       " 'vbp rbs': 756,\n",
       " 'vbp rp': 757,\n",
       " 'vbp to': 758,\n",
       " 'vbp uh': 759,\n",
       " 'vbp vb': 760,\n",
       " 'vbp vbd': 761,\n",
       " 'vbp vbg': 762,\n",
       " 'vbp vbn': 763,\n",
       " 'vbp vbp': 764,\n",
       " 'vbp vbz': 765,\n",
       " 'vbp wdt': 766,\n",
       " 'vbp wp': 767,\n",
       " 'vbp wrb': 768,\n",
       " 'vbz': 769,\n",
       " 'vbz cc': 770,\n",
       " 'vbz cd': 771,\n",
       " 'vbz dt': 772,\n",
       " 'vbz ex': 773,\n",
       " 'vbz fw': 774,\n",
       " 'vbz in': 775,\n",
       " 'vbz jj': 776,\n",
       " 'vbz jjr': 777,\n",
       " 'vbz jjs': 778,\n",
       " 'vbz md': 779,\n",
       " 'vbz nn': 780,\n",
       " 'vbz nnp': 781,\n",
       " 'vbz nns': 782,\n",
       " 'vbz pdt': 783,\n",
       " 'vbz pos': 784,\n",
       " 'vbz prp': 785,\n",
       " 'vbz rb': 786,\n",
       " 'vbz rbr': 787,\n",
       " 'vbz rbs': 788,\n",
       " 'vbz rp': 789,\n",
       " 'vbz to': 790,\n",
       " 'vbz vb': 791,\n",
       " 'vbz vbd': 792,\n",
       " 'vbz vbg': 793,\n",
       " 'vbz vbn': 794,\n",
       " 'vbz vbp': 795,\n",
       " 'vbz vbz': 796,\n",
       " 'vbz wdt': 797,\n",
       " 'vbz wp': 798,\n",
       " 'vbz wrb': 799,\n",
       " 'wdt': 800,\n",
       " 'wdt cc': 801,\n",
       " 'wdt cd': 802,\n",
       " 'wdt dt': 803,\n",
       " 'wdt ex': 804,\n",
       " 'wdt in': 805,\n",
       " 'wdt jj': 806,\n",
       " 'wdt jjr': 807,\n",
       " 'wdt jjs': 808,\n",
       " 'wdt md': 809,\n",
       " 'wdt nn': 810,\n",
       " 'wdt nnp': 811,\n",
       " 'wdt nns': 812,\n",
       " 'wdt pdt': 813,\n",
       " 'wdt prp': 814,\n",
       " 'wdt rb': 815,\n",
       " 'wdt rbr': 816,\n",
       " 'wdt rbs': 817,\n",
       " 'wdt to': 818,\n",
       " 'wdt vb': 819,\n",
       " 'wdt vbd': 820,\n",
       " 'wdt vbg': 821,\n",
       " 'wdt vbn': 822,\n",
       " 'wdt vbp': 823,\n",
       " 'wdt vbz': 824,\n",
       " 'wdt wdt': 825,\n",
       " 'wdt wrb': 826,\n",
       " 'wp': 827,\n",
       " 'wp cc': 828,\n",
       " 'wp cd': 829,\n",
       " 'wp dt': 830,\n",
       " 'wp ex': 831,\n",
       " 'wp fw': 832,\n",
       " 'wp in': 833,\n",
       " 'wp jj': 834,\n",
       " 'wp jjr': 835,\n",
       " 'wp jjs': 836,\n",
       " 'wp md': 837,\n",
       " 'wp nn': 838,\n",
       " 'wp nnp': 839,\n",
       " 'wp nnps': 840,\n",
       " 'wp nns': 841,\n",
       " 'wp pdt': 842,\n",
       " 'wp prp': 843,\n",
       " 'wp rb': 844,\n",
       " 'wp rbr': 845,\n",
       " 'wp to': 846,\n",
       " 'wp vb': 847,\n",
       " 'wp vbd': 848,\n",
       " 'wp vbg': 849,\n",
       " 'wp vbn': 850,\n",
       " 'wp vbp': 851,\n",
       " 'wp vbz': 852,\n",
       " 'wp wdt': 853,\n",
       " 'wp wp': 854,\n",
       " 'wp wrb': 855,\n",
       " 'wrb': 856,\n",
       " 'wrb cc': 857,\n",
       " 'wrb cd': 858,\n",
       " 'wrb dt': 859,\n",
       " 'wrb ex': 860,\n",
       " 'wrb in': 861,\n",
       " 'wrb jj': 862,\n",
       " 'wrb jjr': 863,\n",
       " 'wrb jjs': 864,\n",
       " 'wrb md': 865,\n",
       " 'wrb nn': 866,\n",
       " 'wrb nnp': 867,\n",
       " 'wrb nns': 868,\n",
       " 'wrb pdt': 869,\n",
       " 'wrb prp': 870,\n",
       " 'wrb rb': 871,\n",
       " 'wrb to': 872,\n",
       " 'wrb uh': 873,\n",
       " 'wrb vb': 874,\n",
       " 'wrb vbd': 875,\n",
       " 'wrb vbg': 876,\n",
       " 'wrb vbn': 877,\n",
       " 'wrb vbp': 878,\n",
       " 'wrb vbz': 879,\n",
       " 'wrb wdt': 880,\n",
       " 'wrb wp': 881,\n",
       " 'wrb wrb': 882}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore['phrase_vec'] = explore.phrasing.apply(lambda s: vectorizer.transform(s.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "id26305      (0, 59)\\t1.0\\n  (1, 282)\\t1.0\\n  (3, 467)\\t1...\n",
       "id17569      (0, 434)\\t1.0\\n  (1, 467)\\t1.0\\n  (2, 467)\\t...\n",
       "id11008      (0, 139)\\t1.0\\n  (1, 434)\\t1.0\\n  (2, 172)\\t...\n",
       "id27763      (0, 856)\\t1.0\\n  (1, 467)\\t1.0\\n  (2, 769)\\t...\n",
       "id12958      (0, 675)\\t1.0\\n  (1, 282)\\t1.0\\n  (2, 467)\\t...\n",
       "Name: phrase_vec, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore['phrase_vec'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = explore['phrase_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9622037  -0.9606053  -0.96014828]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', TfidfVectorizer(analyzer = 'word',\n",
    "                                    ngram_range=(1, 2), \n",
    "                                    lowercase=False)),\n",
    "     ('clf', MultinomialNB(alpha=0.1))\n",
    "])\n",
    "print(cross_val_score(pipeline, explore.phrasing, explore.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
